{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=5>Tennessee Fuel Quality Analysis</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Date Published**: 2019/07/31\n",
    "* **Collaborators**: [Kate Hayes](https://github.com/99KHayes) & [Misha Berrien](https://github.com/mishaberrien)\n",
    "* **Data Source**: State of Tennessee Department of Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "\n",
    "src_dir = os.path.join(os.getcwd(), '..', '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# helper functions\n",
    "from d01_data.intermediate_cleaning import concatenate_and_save_intermediate_files, clean_dataset_intermediate_1, clean_dataset_intermediate_2\n",
    "from d03_processing.feature_engineering import merge_gasoline_asm_datasets\n",
    "from d04_modelling.modelling import get_model_pvalue\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction   \n",
    "\n",
    "In this project, we are interested in understanding if we can predict when a fuel compliance test will fail. \n",
    "\n",
    "The state of Tennessee's Department of Agriculture (TDA) maintaines a fuel quality inspection program. Each year, the state inspects all places where fuel is sold/ distributed including gas stations, terminals and airports. The results of these routine tests as well as follow up tests for complaints are maintained by the Tennessee Department of Agriculture. \n",
    "\n",
    "Although around 97% of the tests pass these compliance tests, each year around 3% of the tests fail. A failing test could mean that consumers are exposed to fuel that could do harm to their property or themselves.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tennessee has a Sunshine law (public records law) that allows anyone to request any state record through the right legal channels. The data set was acquired in this manor. We sent an official Tennessee records request for the fuel quality data for the last 5 years. It came in the form of routine inspections and complaints one set for each years, so 10 Excel files in total.\n",
    "\n",
    "Five year fuel quality inspection records\n",
    "for the state of Tennessee\n",
    "\n",
    "* Source: State of Tennessee Department of Agriculture\n",
    "* Time Period: Mid 2014 to early 2019\n",
    "* Number of Fuel Products: 11\n",
    "* Number of Test Types: 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The following key metrics were descriptions given to us by the TDA Fuel Quality Manager. The main thing that we were inspecting in this project was the prediction of pass/fail rates and volatility properties with the seasons.*** \n",
    "\n",
    "Volatility is an important property of gasoline because it must be able to vaporize before combusting in an engine. Three characteristics are used to measure the volatility of gasoline and evaluate suitability: vapor pressure, vapor-liquid ratio, and the distillation temperature at which 50% of the fuel is evaporated.\n",
    "\n",
    "\n",
    "* Vapor pressure is a measure of the amount of vapor that is produced by a gasoline sample at 37.8°C (100°F). Vapor pressure most affects an engine’s ease of starting. The vapor pressure specification is a maximum allowable limit reported in kilopascals. The pressure must be high enough to promote easy starting but not too high to contribute to excessive emissions or vapor lock -  the presence of too much vapor that leads to loss of engine power or rough operation.\n",
    "\n",
    "\n",
    "* Vapor-liquid ratio is the ratio of the volume of vapor to the volume of liquid at atmospheric pressure. The vapor-liquid ratio specification is a minimum allowable limit reported in degrees Celsius. The reported value is the temperature at which the vapor-liquid ratio is equal to 20 (20:1 vol/vol), the approximate temperature at which engine problems may occur. Vapor-liquid ratio is used to evaluate a gasoline sample’s tolerance to changes in temperature. A noncompliant test result (too low) may lead to vapor lock or hot fuel handling problems, as evidenced by loss of power while accelerating or idling.\n",
    "\n",
    "\n",
    "* Distillation measures the temperature range across which a sample is heated to fully evaporate. The temperature at which 50% of a sample is evaporated (T50) relates to the driveability (smoothness and ease of driving) and idling characteristics for the fuel. T50 most similarly relates to how a fuel performs under continuous activity (not starting or warming up). T50 has minimum and maximum allowable limits reported in degrees Celsius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we are interested in two distinct questions: \n",
    "\n",
    "1. Is there seasonality associated with fuel compliance tests failures in the state of Tennessee? \n",
    "1. Can we use data collected by fuel inspectors to better predict gas station fuel test failures in the state of Tennessee?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Datasets \n",
    "\n",
    "The fuel volatility specifications change throughout the year based on outdoor temperature. Therse specifications are set by the ASTM. The ASTM standards were joined onto the five year result data frame. in order to assess the seasonality of the data. A Dicky Fuller test and selective seaonal decomposition was done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicky-Fuller Stationality Tests\n",
    "Once the proper dataframes were created a Dicky Fuller Test was added to assess for stationarity. All of the tests were stationary above a 1% critical value. Two failed at 1% but that was due to extreme sample failures. The average, maximum, and minimum values for each day were taken becasue there was more than one value for each date and time series analysis requires there to be no more than one value for each date. Assessing at these points allowed differing seasonal trends to be seen and the outliers on either side of the spectrum to become more obvious. It is not the most informative thing to say that the value of one sample in Knoxville averaged with another in Nashville can tell the user anything about the trends. It can disguies a lot of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Decomposition\n",
    "A time series decomposition on the average vapor pressure was done. This was selected to do the decomposition becasue it had an easy to see trend of seasonality with few outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Datasets\n",
    "\n",
    "**The functions for cleaning/ processing the dataset can be found in the src/d03_processing folder.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gasoline_proc = pd.read_csv('../../data/03_processed/gasoline_processed.csv')\n",
    "astm = pd.read_csv('../../data/01_raw/ASTM_fuel.csv')\n",
    "astm.columns = ['Date', 'TN_retailers_seasons', 'TN_distributor_seasons',\n",
    "       'vapor_liquid_minC_retail', 'distillation_50_minC _retail',\n",
    "       'distillation_50_maxC_retail', 'vapor_pressure_maxC_retail',\n",
    "       'vapor_liquid_minC_dist', 'distillation_50_minC_dist',\n",
    "       'distillation_50_maxC_dist', 'vapor_pressure_maxC_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3267: DtypeWarning: Columns (0,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3267: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3267: DtypeWarning: Columns (4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "concatenate_and_save_intermediate_files('fy_*_routine', 'routine_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (0,4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "routine_full = pd.read_csv('../../data/02_intermediate/routine_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine_clean = clean_dataset_intermediate_1(routine_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "gasoline_clean = clean_dataset_intermediate_2(routine_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gasoline = merge_gasoline_asm_datasets(gasoline_clean, astm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & Choose Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct features \n",
    "x_feats = ['Grade']\n",
    "X = pd.get_dummies(gasoline[x_feats], dtype=float)\n",
    "X = sm.tools.add_constant(X)\n",
    "# convert target using get_dummies\n",
    "y = pd.get_dummies(gasoline[\"compliance_vap_liq_pressure\"], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y.iloc[:,0], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is heavily imbalanced with a 26:9062 ratio of 1 to 0s. In order to find a reliable result, we need to balance these numbers with oversampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label Count '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Label Count '0': {} \\n\".format(sum(y_train==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "\n",
    "# simple resampling from your previously split data\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Label Count '1': {}\".format(sum(y_train_resampled==1)))\n",
    "print(\"Label Count '0': {} \\n\".format(sum(y_train_resampled==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a balanced dataset to build our models with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Vapor Liquid-Ratio Test Outcome ~ Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12)\n",
    "model_log = logreg.fit(X_train_resampled, y_train_resampled)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find our pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_model_pvalue(y_train_resampled, X_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These pvalues are not significant. Let's try another model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Vapor Liquid-Ratio Test Outcome ~ Tennessee Retailers Season & Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the process laid out above for our second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct features \n",
    "x_feats = ['TN_retailers_seasons', 'grade']\n",
    "X = pd.get_dummies(gasoline[x_feats], dtype=float)\n",
    "X = sm.tools.add_constant(X)\n",
    "# convert target using get_dummies\n",
    "y = pd.get_dummies(gasoline[\"compliance_vap_liq_pressure\"], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y.iloc[:,0], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "\n",
    "# simple resampling from your previously split data\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple resampling from your previously split data\n",
    "X_test_resampled, y_test_resampled = smote.fit_sample(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept = False, C = 1e12)\n",
    "model_log = logreg.fit(X_train_resampled, y_train_resampled)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_pvalue(y_train_resampled, X_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of our models have significant pvalues, but, since we want to understand a bit better about blah blah blah blah, we are going to choose the second model (which have slightly higher pvalues) and move on to our testing phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Chosen Model (Prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_resampled = logreg.predict(X_test_resampled)\n",
    "y_hat_train_resampled = logreg.predict(X_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall, Accuracy and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Precision: ', precision_score(y_hat_train_resampled, y_train_resampled))\n",
    "print('Testing Precision: ', precision_score(y_hat_test_resampled, y_test_resampled))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall: ', recall_score(y_hat_train_resampled, y_train_resampled))\n",
    "print('Testing Recall: ', recall_score(y_hat_test_resampled, y_test_resampled))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy_score(y_hat_train_resampled, y_train_resampled))\n",
    "print('Testing Accuracy: ', accuracy_score(y_hat_test_resampled, y_test_resampled))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score: ',f1_score(y_hat_train_resampled, y_train_resampled))\n",
    "print('Testing F1-Score: ',f1_score(y_hat_test_resampled, y_test_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve & AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First calculate the probability scores of each of the datapoints:\n",
    "y_score = logreg.fit(X_train_resampled, y_train_resampled).decision_function(X_test_resampled)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_resampled, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set_context('poster')\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../../results/Images/roc.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary & Caveats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAH BLAH BLAH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is obvious seasonal trends due to the nature of the regulations.\n",
    "* Further analysis is required in order to interpret the logistic regression.\n",
    "* Do tests that pass but barely pass lead to more complaints?\n",
    "* Do certain regions of Tennessee have more failures in certain seasons\n",
    "* Do certain brands of gas stations or distributors deliver more failures or have more complaints against them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
